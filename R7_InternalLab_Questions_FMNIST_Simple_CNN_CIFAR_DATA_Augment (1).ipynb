{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R7_InternalLab_Questions_FMNIST_Simple_CNN_CIFAR_DATA_Augment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyfMmMnPJjvn",
        "colab_type": "text"
      },
      "source": [
        "## Train a simple convnet on the Fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjcGOJhcJjvp",
        "colab_type": "text"
      },
      "source": [
        "In this, we will see how to deal with image data and train a convnet for image classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR0Pl2XjJjvq",
        "colab_type": "text"
      },
      "source": [
        "### Load the  `fashion_mnist`  dataset\n",
        "\n",
        "** Use keras.datasets to load the dataset **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr75v_UYJjvs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "7c980bcc-eec7-4786-896b-bdfbc355b6b1"
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv70dGjNu3xX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import cifar10, mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Reshape\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTI42-0qJjvw",
        "colab_type": "text"
      },
      "source": [
        "### Find no.of samples are there in training and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2sf67VoJjvx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "7b30f6fd-c275-429c-97c7-5af84d7c7b3c"
      },
      "source": [
        "print('--- THE DATA ---')\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- THE DATA ---\n",
            "x_train shape: (60000, 28, 28)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WytT2eRnJjv4",
        "colab_type": "text"
      },
      "source": [
        "### Find dimensions of an image in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yE-HNLbOrw_D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b3b3ff39-8ef4-4a90-bbe3-6da8a399dcbd"
      },
      "source": [
        "x_train[0].shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gylKXiIluoMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jtdZ7RqJjv8",
        "colab_type": "text"
      },
      "source": [
        "### Convert train and test labels to one hot vectors\n",
        "\n",
        "** check `keras.utils.to_categorical()` **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgHSCXy3JjwA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtjuizv9tLiq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "c281a7fc-3189-4408-d6f8-d258c22e56cd"
      },
      "source": [
        "import pandas as pd\n",
        "y_train_num = pd.Series(y_train).value_counts()\n",
        "y_train_num"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9    6000\n",
              "8    6000\n",
              "7    6000\n",
              "6    6000\n",
              "5    6000\n",
              "4    6000\n",
              "3    6000\n",
              "2    6000\n",
              "1    6000\n",
              "0    6000\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZvCPiOAvd3A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "98c9a559-c950-4197-d08c-85bebd62410e"
      },
      "source": [
        "y_test_num = pd.Series(y_test).value_counts()\n",
        "y_test_num"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7    1000\n",
              "6    1000\n",
              "5    1000\n",
              "4    1000\n",
              "3    1000\n",
              "2    1000\n",
              "9    1000\n",
              "1    1000\n",
              "8    1000\n",
              "0    1000\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4UoO89Vv696",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_num = np_utils.to_categorical(y_train, 10)\n",
        "y_test_num = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO5BRBzBJjwD",
        "colab_type": "text"
      },
      "source": [
        "### Normalize both the train and test image data from 0-255 to 0-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fUQpMHxJjwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da5-DwgrJjwM",
        "colab_type": "text"
      },
      "source": [
        "### Reshape the data from 28x28 to 28x28x1 to match input dimensions in Conv2D layer in keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPGVQ-JJJjwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFRRTJq8JjwQ",
        "colab_type": "text"
      },
      "source": [
        "### Import the necessary layers from keras to build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWTZYnKSJjwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Reshape\n",
        "from keras.layers import Convolution2D, MaxPooling2D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C18AoS7eJjwU",
        "colab_type": "text"
      },
      "source": [
        "T### Build a model \n",
        "\n",
        "** with 2 Conv layers having `32 3x3 filters` in both convolutions with `relu activations` and `flatten` before passing the feature map into 2 fully connected layers (or Dense Layers) having 128 and 10 neurons with `relu` and `softmax` activations respectively. Now, using `categorical_crossentropy` loss with `adam` optimizer train the model with early stopping `patience=5` and no.of `epochs=10`. **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DORCLgSwJjwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN = False\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FNM_LTHzXL0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "outputId": "1f0f8872-e8e1-44e3-de0f-5adbcd96d7b8"
      },
      "source": [
        " # Define model\n",
        "    model2 = Sequential()\n",
        "\n",
        "    # 1st Conv Layer\n",
        "    model2.add(Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n",
        "    model2.add(Activation('relu'))\n",
        "\n",
        "    # 2nd Conv Layer\n",
        "    model2.add(Convolution2D(32, 3, 3))\n",
        "    model2.add(Activation('relu'))\n",
        "\n",
        "    # Fully Connected Layer\n",
        "    model2.add(Flatten())\n",
        "    model2.add(Dense(128))\n",
        "    model2.add(Activation('relu'))\n",
        "\n",
        "    # Prediction Layer\n",
        "    model2.add(Dense(10))\n",
        "    model2.add(Activation('softmax'))\n",
        "\n",
        "    # Loss and Optimizer\n",
        "    model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    # Store Training Results\n",
        "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='auto')\n",
        "    callback_list = [early_stopping]\n",
        "    # Train the model2\n",
        "    model2.fit(x_train, y_train_num, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, \n",
        "              validation_data=(x_test, y_test_num), callbacks=callback_list)\n",
        "\n",
        "    "
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 10s 168us/step - loss: 0.7638 - acc: 0.7218 - val_loss: 0.5991 - val_acc: 0.7694\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 9s 156us/step - loss: 0.5285 - acc: 0.8055 - val_loss: 0.5335 - val_acc: 0.8082\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.4770 - acc: 0.8266 - val_loss: 0.4773 - val_acc: 0.8289\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 9s 157us/step - loss: 0.4447 - acc: 0.8407 - val_loss: 0.4621 - val_acc: 0.8374\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 10s 158us/step - loss: 0.4212 - acc: 0.8491 - val_loss: 0.4413 - val_acc: 0.8368\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 9s 155us/step - loss: 0.4060 - acc: 0.8533 - val_loss: 0.4413 - val_acc: 0.8389\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 0.3889 - acc: 0.8594 - val_loss: 0.4016 - val_acc: 0.8559\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 0.3765 - acc: 0.8637 - val_loss: 0.4182 - val_acc: 0.8454\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 0.3637 - acc: 0.8672 - val_loss: 0.3836 - val_acc: 0.8612\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 9s 154us/step - loss: 0.3517 - acc: 0.8717 - val_loss: 0.4094 - val_acc: 0.8469\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f85705bf630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju69vKdIJjwX",
        "colab_type": "text"
      },
      "source": [
        "### Now, to the above model add `max` pooling layer of `filter size 2x2` and `dropout` layer with `p=0.25` after the 2 conv layers and run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2hAP94vJjwY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "outputId": "d99370c6-a849-4c12-a946-20a135663761"
      },
      "source": [
        " # Define Model\n",
        "    model3 = Sequential()\n",
        "\n",
        "    # 1st Conv Layer\n",
        "    model3.add(Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n",
        "    model3.add(Activation('relu'))\n",
        "\n",
        "    # 2nd Conv Layer\n",
        "    model3.add(Convolution2D(32, 3, 3))\n",
        "    model3.add(Activation('relu'))\n",
        "\n",
        "    # Max Pooling\n",
        "    model3.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    \n",
        "    # Dropout\n",
        "    model3.add(Dropout(0.25))\n",
        "\n",
        "    # Fully Connected Layer\n",
        "    model3.add(Flatten())\n",
        "    model3.add(Dense(128))\n",
        "    model3.add(Activation('relu'))\n",
        "    \n",
        "\n",
        "    # Prediction Layer\n",
        "    model3.add(Dense(10))\n",
        "    model3.add(Activation('softmax'))\n",
        "\n",
        "    # Loss and Optimizer\n",
        "    model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    # Store Training Results\n",
        "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='auto')\n",
        "    callback_list = [early_stopping]\n",
        "\n",
        "    # Train the model\n",
        "    model3.fit(x_train, y_train_num, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, \n",
        "              validation_data=(x_test, y_test_num), callbacks=callback_list)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1...)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 10s 162us/step - loss: 0.7861 - acc: 0.7061 - val_loss: 0.5976 - val_acc: 0.7652\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.5459 - acc: 0.7951 - val_loss: 0.5421 - val_acc: 0.7919\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.5034 - acc: 0.8117 - val_loss: 0.4721 - val_acc: 0.8324\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 9s 142us/step - loss: 0.4705 - acc: 0.8243 - val_loss: 0.4474 - val_acc: 0.8395\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 9s 142us/step - loss: 0.4429 - acc: 0.8361 - val_loss: 0.4582 - val_acc: 0.8210\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.4207 - acc: 0.8437 - val_loss: 0.4358 - val_acc: 0.8376\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.3961 - acc: 0.8541 - val_loss: 0.4066 - val_acc: 0.8490\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 9s 142us/step - loss: 0.3716 - acc: 0.8635 - val_loss: 0.3755 - val_acc: 0.8623\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 9s 152us/step - loss: 0.3487 - acc: 0.8716 - val_loss: 0.3513 - val_acc: 0.8740\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 9s 146us/step - loss: 0.3292 - acc: 0.8785 - val_loss: 0.3306 - val_acc: 0.8808\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f85136c3cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGTA3bfEJjwa",
        "colab_type": "text"
      },
      "source": [
        "### Now, to the above model, lets add Data Augmentation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6gX8n5SJjwb",
        "colab_type": "text"
      },
      "source": [
        "### Import the ImageDataGenrator from keras and fit the training images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cbz4uHBuJjwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# This will do preprocessing and realtime data augmentation:\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    rotation_range=50,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    width_shift_range=0.01,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0.01,  # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=False,  # randomly flip images\n",
        "    vertical_flip=False)  # randomly flip images\n",
        "\n",
        "# Prepare the generator\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl-8dOo7Jjwf",
        "colab_type": "text"
      },
      "source": [
        "#### Showing 5 versions of the first image in training dataset using image datagenerator.flow()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "DpI1_McYJjwg",
        "colab_type": "code",
        "outputId": "c2ac57e0-03be-479d-cdbc-2c296203c8fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "gen = datagen.flow(x_train[0:1], batch_size=1)\n",
        "for i in range(1, 6):\n",
        "    plt.subplot(1,5,i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
        "    plt.plot()\n",
        "plt.show()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABICAYAAABV5CYrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIpHoIv4D8Hs0ptsjExAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmPl5yE8Jjwm",
        "colab_type": "text"
      },
      "source": [
        "### Run the above model using fit_generator()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44ZnDdJYJjwn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "outputId": "a75167c5-2155-4e92-d4d4-4bfce81f7bca"
      },
      "source": [
        "model3.fit_generator(datagen.flow(x_train, y_train_num,batch_size=32),\n",
        "                    samples_per_epoch=x_train.shape[0],\n",
        "                    nb_epoch=10,\n",
        "                    validation_data=(x_test, y_test_num), callbacks=callback_list)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "  15/1875 [..............................] - ETA: 21s - loss: 1.8231 - acc: 0.4250"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., callbacks=[<keras.ca..., steps_per_epoch=1875, epochs=10)`\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.6835 - acc: 0.7489 - val_loss: 0.4153 - val_acc: 0.8572\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.5394 - acc: 0.8035 - val_loss: 0.4078 - val_acc: 0.8612\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.5031 - acc: 0.8175 - val_loss: 0.3928 - val_acc: 0.8668\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.4749 - acc: 0.8290 - val_loss: 0.4132 - val_acc: 0.8572\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.4547 - acc: 0.8354 - val_loss: 0.3908 - val_acc: 0.8658\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.4427 - acc: 0.8383 - val_loss: 0.3755 - val_acc: 0.8700\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.4324 - acc: 0.8424 - val_loss: 0.3805 - val_acc: 0.8687\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.4177 - acc: 0.8476 - val_loss: 0.3790 - val_acc: 0.8710\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.4143 - acc: 0.8485 - val_loss: 0.3757 - val_acc: 0.8687\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.4093 - acc: 0.8507 - val_loss: 0.3800 - val_acc: 0.8734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f858541a1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwQQW5iOJjwq",
        "colab_type": "text"
      },
      "source": [
        "###  Report the final train and validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1SrtBEPJjwq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "17d663e2-bfc1-43ff-99ae-49adbad3f9dd"
      },
      "source": [
        "loss_and_metrics = model3.evaluate(x_train, y_train_num)\n",
        "print(loss_and_metrics)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 3s 51us/step\n",
            "[0.32532964313328266, 0.8854833333333333]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBwVWNQC2qZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KXqmUDW2rM1",
        "colab_type": "text"
      },
      "source": [
        "## **DATA AUGMENTATION ON CIFAR10 DATASET**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mja6OgQ3L18",
        "colab_type": "text"
      },
      "source": [
        "One of the best ways to improve the performance of a Deep Learning model is to add more data to the training set. Aside from gathering more instances from the wild that are representative of the distinction task, we want to develop a set of methods that enhance the data we already have. There are many ways to augment existing datasets and produce more robust models. In the image domain, these are done to utilize the full power of the convolutional neural network, which is able to capture translational invariance. This translational invariance is what makes image recognition such a difficult task in the first place. You want the dataset to be representative of the many different positions, angles, lightings, and miscellaneous distortions that are of interest to the vision task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HzVTPUM3WZJ",
        "colab_type": "text"
      },
      "source": [
        "### **Import neessary libraries for data augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPM558TX4KMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#already explained above"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6hicLwP4SqY",
        "colab_type": "text"
      },
      "source": [
        "### **Load CIFAR10 dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ1WzrXd4WNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IxCEk37FhCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n28ccU6Hp6s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "af0a86c0-83c8-4051-8df0-f424236a05cc"
      },
      "source": [
        "tf.keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([[[[ 59,  62,  63],\n",
              "           [ 43,  46,  45],\n",
              "           [ 50,  48,  43],\n",
              "           ...,\n",
              "           [158, 132, 108],\n",
              "           [152, 125, 102],\n",
              "           [148, 124, 103]],\n",
              "  \n",
              "          [[ 16,  20,  20],\n",
              "           [  0,   0,   0],\n",
              "           [ 18,   8,   0],\n",
              "           ...,\n",
              "           [123,  88,  55],\n",
              "           [119,  83,  50],\n",
              "           [122,  87,  57]],\n",
              "  \n",
              "          [[ 25,  24,  21],\n",
              "           [ 16,   7,   0],\n",
              "           [ 49,  27,   8],\n",
              "           ...,\n",
              "           [118,  84,  50],\n",
              "           [120,  84,  50],\n",
              "           [109,  73,  42]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[208, 170,  96],\n",
              "           [201, 153,  34],\n",
              "           [198, 161,  26],\n",
              "           ...,\n",
              "           [160, 133,  70],\n",
              "           [ 56,  31,   7],\n",
              "           [ 53,  34,  20]],\n",
              "  \n",
              "          [[180, 139,  96],\n",
              "           [173, 123,  42],\n",
              "           [186, 144,  30],\n",
              "           ...,\n",
              "           [184, 148,  94],\n",
              "           [ 97,  62,  34],\n",
              "           [ 83,  53,  34]],\n",
              "  \n",
              "          [[177, 144, 116],\n",
              "           [168, 129,  94],\n",
              "           [179, 142,  87],\n",
              "           ...,\n",
              "           [216, 184, 140],\n",
              "           [151, 118,  84],\n",
              "           [123,  92,  72]]],\n",
              "  \n",
              "  \n",
              "         [[[154, 177, 187],\n",
              "           [126, 137, 136],\n",
              "           [105, 104,  95],\n",
              "           ...,\n",
              "           [ 91,  95,  71],\n",
              "           [ 87,  90,  71],\n",
              "           [ 79,  81,  70]],\n",
              "  \n",
              "          [[140, 160, 169],\n",
              "           [145, 153, 154],\n",
              "           [125, 125, 118],\n",
              "           ...,\n",
              "           [ 96,  99,  78],\n",
              "           [ 77,  80,  62],\n",
              "           [ 71,  73,  61]],\n",
              "  \n",
              "          [[140, 155, 164],\n",
              "           [139, 146, 149],\n",
              "           [115, 115, 112],\n",
              "           ...,\n",
              "           [ 79,  82,  64],\n",
              "           [ 68,  70,  55],\n",
              "           [ 67,  69,  55]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[175, 167, 166],\n",
              "           [156, 154, 160],\n",
              "           [154, 160, 170],\n",
              "           ...,\n",
              "           [ 42,  34,  36],\n",
              "           [ 61,  53,  57],\n",
              "           [ 93,  83,  91]],\n",
              "  \n",
              "          [[165, 154, 128],\n",
              "           [156, 152, 130],\n",
              "           [159, 161, 142],\n",
              "           ...,\n",
              "           [103,  93,  96],\n",
              "           [123, 114, 120],\n",
              "           [131, 121, 131]],\n",
              "  \n",
              "          [[163, 148, 120],\n",
              "           [158, 148, 122],\n",
              "           [163, 156, 133],\n",
              "           ...,\n",
              "           [143, 133, 139],\n",
              "           [143, 134, 142],\n",
              "           [143, 133, 144]]],\n",
              "  \n",
              "  \n",
              "         [[[255, 255, 255],\n",
              "           [253, 253, 253],\n",
              "           [253, 253, 253],\n",
              "           ...,\n",
              "           [253, 253, 253],\n",
              "           [253, 253, 253],\n",
              "           [253, 253, 253]],\n",
              "  \n",
              "          [[255, 255, 255],\n",
              "           [255, 255, 255],\n",
              "           [255, 255, 255],\n",
              "           ...,\n",
              "           [255, 255, 255],\n",
              "           [255, 255, 255],\n",
              "           [255, 255, 255]],\n",
              "  \n",
              "          [[255, 255, 255],\n",
              "           [254, 254, 254],\n",
              "           [254, 254, 254],\n",
              "           ...,\n",
              "           [254, 254, 254],\n",
              "           [254, 254, 254],\n",
              "           [254, 254, 254]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[113, 120, 112],\n",
              "           [111, 118, 111],\n",
              "           [105, 112, 106],\n",
              "           ...,\n",
              "           [ 72,  81,  80],\n",
              "           [ 72,  80,  79],\n",
              "           [ 72,  80,  79]],\n",
              "  \n",
              "          [[111, 118, 110],\n",
              "           [104, 111, 104],\n",
              "           [ 99, 106,  98],\n",
              "           ...,\n",
              "           [ 68,  75,  73],\n",
              "           [ 70,  76,  75],\n",
              "           [ 78,  84,  82]],\n",
              "  \n",
              "          [[106, 113, 105],\n",
              "           [ 99, 106,  98],\n",
              "           [ 95, 102,  94],\n",
              "           ...,\n",
              "           [ 78,  85,  83],\n",
              "           [ 79,  85,  83],\n",
              "           [ 80,  86,  84]]],\n",
              "  \n",
              "  \n",
              "         ...,\n",
              "  \n",
              "  \n",
              "         [[[ 35, 178, 235],\n",
              "           [ 40, 176, 239],\n",
              "           [ 42, 176, 241],\n",
              "           ...,\n",
              "           [ 99, 177, 219],\n",
              "           [ 79, 147, 197],\n",
              "           [ 89, 148, 189]],\n",
              "  \n",
              "          [[ 57, 182, 234],\n",
              "           [ 44, 184, 250],\n",
              "           [ 50, 183, 240],\n",
              "           ...,\n",
              "           [156, 182, 200],\n",
              "           [141, 177, 206],\n",
              "           [116, 149, 175]],\n",
              "  \n",
              "          [[ 98, 197, 237],\n",
              "           [ 64, 189, 252],\n",
              "           [ 69, 192, 245],\n",
              "           ...,\n",
              "           [188, 195, 206],\n",
              "           [119, 135, 147],\n",
              "           [ 61,  79,  90]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[ 73,  79,  77],\n",
              "           [ 53,  63,  68],\n",
              "           [ 54,  68,  80],\n",
              "           ...,\n",
              "           [ 17,  40,  64],\n",
              "           [ 21,  36,  51],\n",
              "           [ 33,  48,  49]],\n",
              "  \n",
              "          [[ 61,  68,  75],\n",
              "           [ 55,  70,  86],\n",
              "           [ 57,  79, 103],\n",
              "           ...,\n",
              "           [ 24,  48,  72],\n",
              "           [ 17,  35,  53],\n",
              "           [  7,  23,  32]],\n",
              "  \n",
              "          [[ 44,  56,  73],\n",
              "           [ 46,  66,  88],\n",
              "           [ 49,  77, 105],\n",
              "           ...,\n",
              "           [ 27,  52,  77],\n",
              "           [ 21,  43,  66],\n",
              "           [ 12,  31,  50]]],\n",
              "  \n",
              "  \n",
              "         [[[189, 211, 240],\n",
              "           [186, 208, 236],\n",
              "           [185, 207, 235],\n",
              "           ...,\n",
              "           [175, 195, 224],\n",
              "           [172, 194, 222],\n",
              "           [169, 194, 220]],\n",
              "  \n",
              "          [[194, 210, 239],\n",
              "           [191, 207, 236],\n",
              "           [190, 206, 235],\n",
              "           ...,\n",
              "           [173, 192, 220],\n",
              "           [171, 191, 218],\n",
              "           [167, 190, 216]],\n",
              "  \n",
              "          [[208, 219, 244],\n",
              "           [205, 216, 240],\n",
              "           [204, 215, 239],\n",
              "           ...,\n",
              "           [175, 191, 217],\n",
              "           [172, 190, 216],\n",
              "           [169, 191, 215]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[207, 199, 181],\n",
              "           [203, 195, 175],\n",
              "           [203, 196, 173],\n",
              "           ...,\n",
              "           [135, 132, 127],\n",
              "           [162, 158, 150],\n",
              "           [168, 163, 151]],\n",
              "  \n",
              "          [[198, 190, 170],\n",
              "           [189, 181, 159],\n",
              "           [180, 172, 147],\n",
              "           ...,\n",
              "           [178, 171, 160],\n",
              "           [175, 169, 156],\n",
              "           [175, 169, 154]],\n",
              "  \n",
              "          [[198, 189, 173],\n",
              "           [189, 181, 162],\n",
              "           [178, 170, 149],\n",
              "           ...,\n",
              "           [195, 184, 169],\n",
              "           [196, 189, 171],\n",
              "           [195, 190, 171]]],\n",
              "  \n",
              "  \n",
              "         [[[229, 229, 239],\n",
              "           [236, 237, 247],\n",
              "           [234, 236, 247],\n",
              "           ...,\n",
              "           [217, 219, 233],\n",
              "           [221, 223, 234],\n",
              "           [222, 223, 233]],\n",
              "  \n",
              "          [[222, 221, 229],\n",
              "           [239, 239, 249],\n",
              "           [233, 234, 246],\n",
              "           ...,\n",
              "           [223, 223, 236],\n",
              "           [227, 228, 238],\n",
              "           [210, 211, 220]],\n",
              "  \n",
              "          [[213, 206, 211],\n",
              "           [234, 232, 239],\n",
              "           [231, 233, 244],\n",
              "           ...,\n",
              "           [220, 220, 232],\n",
              "           [220, 219, 232],\n",
              "           [202, 203, 215]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[150, 143, 135],\n",
              "           [140, 135, 127],\n",
              "           [132, 127, 120],\n",
              "           ...,\n",
              "           [224, 222, 218],\n",
              "           [230, 228, 225],\n",
              "           [241, 241, 238]],\n",
              "  \n",
              "          [[137, 132, 126],\n",
              "           [130, 127, 120],\n",
              "           [125, 121, 115],\n",
              "           ...,\n",
              "           [181, 180, 178],\n",
              "           [202, 201, 198],\n",
              "           [212, 211, 207]],\n",
              "  \n",
              "          [[122, 119, 114],\n",
              "           [118, 116, 110],\n",
              "           [120, 116, 111],\n",
              "           ...,\n",
              "           [179, 177, 173],\n",
              "           [164, 164, 162],\n",
              "           [163, 163, 161]]]], dtype=uint8), array([[6],\n",
              "         [9],\n",
              "         [9],\n",
              "         ...,\n",
              "         [9],\n",
              "         [1],\n",
              "         [1]], dtype=uint8)), (array([[[[158, 112,  49],\n",
              "           [159, 111,  47],\n",
              "           [165, 116,  51],\n",
              "           ...,\n",
              "           [137,  95,  36],\n",
              "           [126,  91,  36],\n",
              "           [116,  85,  33]],\n",
              "  \n",
              "          [[152, 112,  51],\n",
              "           [151, 110,  40],\n",
              "           [159, 114,  45],\n",
              "           ...,\n",
              "           [136,  95,  31],\n",
              "           [125,  91,  32],\n",
              "           [119,  88,  34]],\n",
              "  \n",
              "          [[151, 110,  47],\n",
              "           [151, 109,  33],\n",
              "           [158, 111,  36],\n",
              "           ...,\n",
              "           [139,  98,  34],\n",
              "           [130,  95,  34],\n",
              "           [120,  89,  33]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[ 68, 124, 177],\n",
              "           [ 42, 100, 148],\n",
              "           [ 31,  88, 137],\n",
              "           ...,\n",
              "           [ 38,  97, 146],\n",
              "           [ 13,  64, 108],\n",
              "           [ 40,  85, 127]],\n",
              "  \n",
              "          [[ 61, 116, 168],\n",
              "           [ 49, 102, 148],\n",
              "           [ 35,  85, 132],\n",
              "           ...,\n",
              "           [ 26,  82, 130],\n",
              "           [ 29,  82, 126],\n",
              "           [ 20,  64, 107]],\n",
              "  \n",
              "          [[ 54, 107, 160],\n",
              "           [ 56, 105, 149],\n",
              "           [ 45,  89, 132],\n",
              "           ...,\n",
              "           [ 24,  77, 124],\n",
              "           [ 34,  84, 129],\n",
              "           [ 21,  67, 110]]],\n",
              "  \n",
              "  \n",
              "         [[[235, 235, 235],\n",
              "           [231, 231, 231],\n",
              "           [232, 232, 232],\n",
              "           ...,\n",
              "           [233, 233, 233],\n",
              "           [233, 233, 233],\n",
              "           [232, 232, 232]],\n",
              "  \n",
              "          [[238, 238, 238],\n",
              "           [235, 235, 235],\n",
              "           [235, 235, 235],\n",
              "           ...,\n",
              "           [236, 236, 236],\n",
              "           [236, 236, 236],\n",
              "           [235, 235, 235]],\n",
              "  \n",
              "          [[237, 237, 237],\n",
              "           [234, 234, 234],\n",
              "           [234, 234, 234],\n",
              "           ...,\n",
              "           [235, 235, 235],\n",
              "           [235, 235, 235],\n",
              "           [234, 234, 234]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[ 87,  99,  89],\n",
              "           [ 43,  51,  37],\n",
              "           [ 19,  23,  11],\n",
              "           ...,\n",
              "           [169, 184, 179],\n",
              "           [182, 197, 193],\n",
              "           [188, 202, 201]],\n",
              "  \n",
              "          [[ 82,  96,  82],\n",
              "           [ 46,  57,  36],\n",
              "           [ 36,  44,  22],\n",
              "           ...,\n",
              "           [174, 189, 183],\n",
              "           [185, 200, 196],\n",
              "           [187, 202, 200]],\n",
              "  \n",
              "          [[ 85, 101,  83],\n",
              "           [ 62,  75,  48],\n",
              "           [ 58,  67,  38],\n",
              "           ...,\n",
              "           [168, 183, 178],\n",
              "           [180, 195, 191],\n",
              "           [186, 200, 199]]],\n",
              "  \n",
              "  \n",
              "         [[[158, 190, 222],\n",
              "           [158, 187, 218],\n",
              "           [139, 166, 194],\n",
              "           ...,\n",
              "           [228, 231, 234],\n",
              "           [237, 239, 243],\n",
              "           [238, 241, 246]],\n",
              "  \n",
              "          [[170, 200, 229],\n",
              "           [172, 199, 226],\n",
              "           [151, 176, 201],\n",
              "           ...,\n",
              "           [232, 232, 236],\n",
              "           [246, 246, 250],\n",
              "           [246, 247, 251]],\n",
              "  \n",
              "          [[174, 201, 225],\n",
              "           [176, 200, 222],\n",
              "           [157, 179, 199],\n",
              "           ...,\n",
              "           [230, 229, 232],\n",
              "           [250, 249, 251],\n",
              "           [245, 244, 247]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[ 31,  40,  45],\n",
              "           [ 30,  39,  44],\n",
              "           [ 26,  35,  40],\n",
              "           ...,\n",
              "           [ 37,  40,  46],\n",
              "           [  9,  13,  14],\n",
              "           [  4,   7,   5]],\n",
              "  \n",
              "          [[ 23,  34,  39],\n",
              "           [ 27,  38,  43],\n",
              "           [ 25,  36,  41],\n",
              "           ...,\n",
              "           [ 19,  20,  24],\n",
              "           [  4,   6,   3],\n",
              "           [  5,   7,   3]],\n",
              "  \n",
              "          [[ 28,  41,  47],\n",
              "           [ 30,  43,  50],\n",
              "           [ 32,  45,  52],\n",
              "           ...,\n",
              "           [  5,   6,   8],\n",
              "           [  4,   5,   3],\n",
              "           [  7,   8,   7]]],\n",
              "  \n",
              "  \n",
              "         ...,\n",
              "  \n",
              "  \n",
              "         [[[ 20,  15,  12],\n",
              "           [ 19,  14,  11],\n",
              "           [ 15,  14,  11],\n",
              "           ...,\n",
              "           [ 10,   9,   7],\n",
              "           [ 12,  11,   9],\n",
              "           [ 13,  12,  10]],\n",
              "  \n",
              "          [[ 21,  16,  13],\n",
              "           [ 20,  16,  13],\n",
              "           [ 18,  17,  12],\n",
              "           ...,\n",
              "           [ 10,   9,   7],\n",
              "           [ 10,   9,   7],\n",
              "           [ 12,  11,   9]],\n",
              "  \n",
              "          [[ 21,  16,  13],\n",
              "           [ 21,  17,  12],\n",
              "           [ 20,  18,  11],\n",
              "           ...,\n",
              "           [ 12,  11,   9],\n",
              "           [ 12,  11,   9],\n",
              "           [ 13,  12,  10]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[ 33,  25,  13],\n",
              "           [ 34,  26,  15],\n",
              "           [ 34,  26,  15],\n",
              "           ...,\n",
              "           [ 28,  25,  52],\n",
              "           [ 29,  25,  58],\n",
              "           [ 23,  20,  42]],\n",
              "  \n",
              "          [[ 33,  25,  14],\n",
              "           [ 34,  26,  15],\n",
              "           [ 34,  26,  15],\n",
              "           ...,\n",
              "           [ 27,  24,  52],\n",
              "           [ 27,  24,  56],\n",
              "           [ 25,  22,  47]],\n",
              "  \n",
              "          [[ 31,  23,  12],\n",
              "           [ 32,  24,  13],\n",
              "           [ 33,  25,  14],\n",
              "           ...,\n",
              "           [ 24,  23,  50],\n",
              "           [ 26,  23,  53],\n",
              "           [ 25,  20,  47]]],\n",
              "  \n",
              "  \n",
              "         [[[ 25,  40,  12],\n",
              "           [ 15,  36,   3],\n",
              "           [ 23,  41,  18],\n",
              "           ...,\n",
              "           [ 61,  82,  78],\n",
              "           [ 92, 113, 112],\n",
              "           [ 75,  89,  92]],\n",
              "  \n",
              "          [[ 12,  25,   6],\n",
              "           [ 20,  37,   7],\n",
              "           [ 24,  36,  15],\n",
              "           ...,\n",
              "           [115, 134, 138],\n",
              "           [149, 168, 177],\n",
              "           [104, 117, 131]],\n",
              "  \n",
              "          [[ 12,  25,  11],\n",
              "           [ 15,  29,   6],\n",
              "           [ 34,  40,  24],\n",
              "           ...,\n",
              "           [154, 172, 182],\n",
              "           [157, 175, 192],\n",
              "           [116, 129, 151]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[100, 129,  81],\n",
              "           [103, 132,  84],\n",
              "           [104, 134,  86],\n",
              "           ...,\n",
              "           [ 97, 128,  84],\n",
              "           [ 98, 126,  84],\n",
              "           [ 91, 121,  79]],\n",
              "  \n",
              "          [[103, 132,  83],\n",
              "           [104, 131,  83],\n",
              "           [107, 135,  87],\n",
              "           ...,\n",
              "           [101, 132,  87],\n",
              "           [ 99, 127,  84],\n",
              "           [ 92, 121,  79]],\n",
              "  \n",
              "          [[ 95, 126,  78],\n",
              "           [ 95, 123,  76],\n",
              "           [101, 128,  81],\n",
              "           ...,\n",
              "           [ 93, 124,  80],\n",
              "           [ 95, 123,  81],\n",
              "           [ 92, 120,  80]]],\n",
              "  \n",
              "  \n",
              "         [[[ 73,  78,  75],\n",
              "           [ 98, 103, 113],\n",
              "           [ 99, 106, 114],\n",
              "           ...,\n",
              "           [135, 150, 152],\n",
              "           [135, 149, 154],\n",
              "           [203, 215, 223]],\n",
              "  \n",
              "          [[ 69,  73,  70],\n",
              "           [ 84,  89,  97],\n",
              "           [ 68,  75,  81],\n",
              "           ...,\n",
              "           [ 85,  95,  89],\n",
              "           [ 71,  82,  80],\n",
              "           [120, 133, 135]],\n",
              "  \n",
              "          [[ 69,  73,  70],\n",
              "           [ 90,  95, 100],\n",
              "           [ 62,  71,  74],\n",
              "           ...,\n",
              "           [ 74,  81,  70],\n",
              "           [ 53,  62,  54],\n",
              "           [ 62,  74,  69]],\n",
              "  \n",
              "          ...,\n",
              "  \n",
              "          [[123, 128,  96],\n",
              "           [132, 132, 102],\n",
              "           [129, 128, 100],\n",
              "           ...,\n",
              "           [108, 107,  88],\n",
              "           [ 62,  60,  55],\n",
              "           [ 27,  27,  28]],\n",
              "  \n",
              "          [[115, 121,  91],\n",
              "           [123, 124,  95],\n",
              "           [129, 126,  99],\n",
              "           ...,\n",
              "           [115, 116,  94],\n",
              "           [ 66,  65,  59],\n",
              "           [ 27,  27,  27]],\n",
              "  \n",
              "          [[116, 120,  90],\n",
              "           [121, 122,  94],\n",
              "           [129, 128, 101],\n",
              "           ...,\n",
              "           [116, 115,  94],\n",
              "           [ 68,  65,  58],\n",
              "           [ 27,  26,  26]]]], dtype=uint8), array([[3],\n",
              "         [8],\n",
              "         [8],\n",
              "         ...,\n",
              "         [5],\n",
              "         [1],\n",
              "         [7]], dtype=uint8)))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnJvUNCwGwoQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train,y_train),(x_test,y_test) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN3vYYhK4W0u",
        "colab_type": "text"
      },
      "source": [
        "### **Create a data_gen funtion to genererator with image rotation,shifting image horizontally and vertically with random flip horizontally.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJbekTKi4cmM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# This will do preprocessing and realtime data augmentation:\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "    samplewise_center=False,  # set each sample mean to 0\n",
        "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "    samplewise_std_normalization=False,  # divide each input by its std\n",
        "    zca_whitening=False,  # apply ZCA whitening\n",
        "    rotation_range=50,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    width_shift_range=0.01,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0.01,  # randomly shift images vertically (fraction of total height)\n",
        "    horizontal_flip=False,  # randomly flip images\n",
        "    vertical_flip=False)  # randomly flip images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-SLtUhC4dK2",
        "colab_type": "text"
      },
      "source": [
        "### **Prepare/fit the generator.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSw8Bv2_4hb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare the generator\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYyF-P8O4jQ8",
        "colab_type": "text"
      },
      "source": [
        "### **Generate 5 images for 1 of the image of CIFAR10 train dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4hNE8z9HV4l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXug4z234mwQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "953dbd18-1a13-481e-c55b-20d8b4f28352"
      },
      "source": [
        "plt.imshow(x_train[0].squeeze(), cmap='gray')\n",
        "plt.plot()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zTIhb5uHTeM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "3af9cf3e-7160-4059-d439-fc7e2acb34d5"
      },
      "source": [
        "gen = datagen.flow(x_train[:1], batch_size=1)\n",
        "for i in range(1, 6):    \n",
        "    plt.subplot(1,5,i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(gen.next().squeeze().astype('uint8'), cmap='gray')\n",
        "    plt.plot()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABICAYAAABV5CYrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nemhrnAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ishTB-L7HeKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}